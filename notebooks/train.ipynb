{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from lib.service import SamplesService\n",
    "from lib.ranger import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int64_bitset(x):\n",
    "    \"\"\"\n",
    "    Convert a 64-bit integer into a 64-element float tensor\n",
    "    \"\"\"\n",
    "    masks = 2 ** torch.arange(64, dtype=torch.int64, device='cuda')\n",
    "    expanded = torch.bitwise_and(x.unsqueeze(-1), masks).ne(0).to(torch.float32)\n",
    "    return expanded\n",
    "\n",
    "intermediate_scale = 1 / 64\n",
    "output_scale = 1 / 9600\n",
    "\n",
    "class ChessModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(ChessModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(num_features, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 64)\n",
    "        self.linear3 = torch.nn.Linear(64, 64)\n",
    "        self.output = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0) # Clipped ReLU\n",
    "        x = self.linear2(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0) # Clipped ReLU\n",
    "        x = self.linear3(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0) # Clipped ReLU\n",
    "\n",
    "        # since we are clipping the layers, we need to scale the output so it can reach higher values\n",
    "        return self.output(x) * 600.0\n",
    "    \n",
    "    def _clip_weights(self):\n",
    "        intermediate_clip = 127 * intermediate_scale\n",
    "        output_clip = 127*127 * output_scale\n",
    "\n",
    "        self.linear1.weight.data.clamp_(-intermediate_clip, intermediate_clip)\n",
    "        self.linear2.weight.data.clamp_(-intermediate_clip, intermediate_clip)\n",
    "        self.linear3.weight.data.clamp_(-intermediate_clip, intermediate_clip)\n",
    "        self.output.weight.data.clamp_(-output_clip, output_clip)\n",
    "\n",
    "    def _layer_json(self, layer, scale_value):\n",
    "        weights = layer.weight.data.cpu().numpy()\n",
    "        bias = layer.bias.data.cpu().numpy()\n",
    "\n",
    "        qweights = np.round(weights / scale_value).astype('int8')\n",
    "        qbias = np.round(bias).astype('int32')\n",
    "\n",
    "        return {\n",
    "            \"in_features\": layer.in_features,\n",
    "            \"out_features\": layer.out_features,\n",
    "            \"weights\": qweights.tolist(),\n",
    "            \"bias\": qbias.tolist()\n",
    "        }\n",
    "\n",
    "    def to_json(self):\n",
    "        \"\"\"\n",
    "        Returns the layers of the model as a list of dictionaries\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "\n",
    "        for layer in [self.linear1, self.linear2, self.linear3]:\n",
    "            layers.append(self._layer_json(layer, intermediate_scale))\n",
    "        layers.append(self._layer_json(layer, output_scale))\n",
    "\n",
    "        return layers\n",
    "\n",
    "#testmodel = ChessModel(768)\n",
    "#testmodel.load_state_dict(torch.load('/mnt/c/Users/mlomb/Desktop/Tesis/cs-master-thesis/notebooks/runs/20240308_130550_eval_basic_4096/models/400.pth'))\n",
    "#testmodel.cuda()\n",
    "\n",
    "#X, y = samples_service.next_batch()\n",
    "#X = decode_int64_bitset(X)\n",
    "#X = X.reshape(-1, NUM_FEATURES)\n",
    "#print(testmodel(X) / 356 * 100, y)\n",
    "\n",
    "#import json\n",
    "#with open('model.json', 'w') as f:\n",
    "#    f.write(json.dumps(testmodel.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQRLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PQRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred):\n",
    "        pred = pred.reshape(-1, 3)\n",
    "        \n",
    "        p = pred[:,0]\n",
    "        q = pred[:,1]\n",
    "        r = pred[:,2]\n",
    "        \n",
    "        a = -torch.mean(torch.log(torch.sigmoid(r - q)))\n",
    "        b = torch.mean(torch.square(p + q))\n",
    "\n",
    "        loss = a + b\n",
    "\n",
    "        return loss\n",
    "\n",
    "class EvalLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EvalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        scaling = 356.0\n",
    "\n",
    "        # scale CP score to engine units [-10_000, 10_000]\n",
    "        target = target * scaling / 100.0\n",
    "\n",
    "        # targets are in CP-space change it to WDL-space [0, 1]\n",
    "        wdl_model = torch.sigmoid(output / scaling)\n",
    "        wdl_target = torch.sigmoid(target / scaling)\n",
    "\n",
    "        loss = torch.pow(torch.abs(wdl_model - wdl_target), 2.5)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 12:57:52.766866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 12:57:52.766915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 12:57:52.768351: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-09 12:57:52.775394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 12:57:53.801383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1000/1000 [00:07<00:00, 128.17it/s]\n",
      "Epoch 1: 100%|██████████| 1000/1000 [00:08<00:00, 118.42it/s]\n",
      "Epoch 2: 100%|██████████| 1000/1000 [00:08<00:00, 114.82it/s]\n",
      "Epoch 3: 100%|██████████| 1000/1000 [00:08<00:00, 116.63it/s]\n",
      "Epoch 4: 100%|██████████| 1000/1000 [00:08<00:00, 117.83it/s]\n",
      "Epoch 5: 100%|██████████| 1000/1000 [00:08<00:00, 120.94it/s]\n",
      "Epoch 6: 100%|██████████| 1000/1000 [00:08<00:00, 115.83it/s]\n",
      "Epoch 7: 100%|██████████| 1000/1000 [00:08<00:00, 119.38it/s]\n",
      "Epoch 8: 100%|██████████| 1000/1000 [00:07<00:00, 128.47it/s]\n",
      "Epoch 9: 100%|██████████| 1000/1000 [00:07<00:00, 132.69it/s]\n",
      "Epoch 10: 100%|██████████| 1000/1000 [00:07<00:00, 138.27it/s]\n",
      "Epoch 11: 100%|██████████| 1000/1000 [00:07<00:00, 131.66it/s]\n",
      "Epoch 12: 100%|██████████| 1000/1000 [00:07<00:00, 136.83it/s]\n",
      "Epoch 13: 100%|██████████| 1000/1000 [00:07<00:00, 129.16it/s]\n",
      "Epoch 14: 100%|██████████| 1000/1000 [00:07<00:00, 138.08it/s]\n",
      "Epoch 15: 100%|██████████| 1000/1000 [00:08<00:00, 119.23it/s]\n",
      "Epoch 16: 100%|██████████| 1000/1000 [00:09<00:00, 105.22it/s]\n",
      "Epoch 17: 100%|██████████| 1000/1000 [00:08<00:00, 111.57it/s]\n",
      "Epoch 18: 100%|██████████| 1000/1000 [00:08<00:00, 111.96it/s]\n",
      "Epoch 19: 100%|██████████| 1000/1000 [00:08<00:00, 123.24it/s]\n",
      "Epoch 20: 100%|██████████| 1000/1000 [00:08<00:00, 120.18it/s]\n",
      "Epoch 21: 100%|██████████| 1000/1000 [00:08<00:00, 123.54it/s]\n",
      "Epoch 22: 100%|██████████| 1000/1000 [00:08<00:00, 123.93it/s]\n",
      "Epoch 23: 100%|██████████| 1000/1000 [00:09<00:00, 109.03it/s]\n",
      "Epoch 24: 100%|██████████| 1000/1000 [00:09<00:00, 106.52it/s]\n",
      "Epoch 25: 100%|██████████| 1000/1000 [00:09<00:00, 106.38it/s]\n",
      "Epoch 26: 100%|██████████| 1000/1000 [00:09<00:00, 105.24it/s]\n",
      "Epoch 27: 100%|██████████| 1000/1000 [00:08<00:00, 119.40it/s]\n",
      "Epoch 28:  83%|████████▎ | 832/1000 [00:07<00:01, 112.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(BATCHES_PER_EPOCH), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43msamples_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# expand bitset\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     X \u001b[38;5;241m=\u001b[39m decode_int64_bitset(X)\n",
      "File \u001b[0;32m/mnt/c/Users/mlomb/Desktop/Tesis/cs-master-thesis/notebooks/../lib/service.py:63\u001b[0m, in \u001b[0;36mSamplesService.next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mGets the next batch of samples.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    A TensorFlow tensor containing the next batch of samples.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Wait until batch is ready\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_ready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Create PyTorch tensors using the numpy arrays.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# This will copy the data into the device, so after this line we don't care about self.data/x/y\u001b[39;00m\n\u001b[1;32m     67\u001b[0m x_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/mlomb/Desktop/Tesis/cs-master-thesis/notebooks/../lib/service.py:45\u001b[0m, in \u001b[0;36mSamplesService.wait_until_ready\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_until_ready\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    Waits until the generator has written the next batch of samples into the shared memory.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "EPOCHS = 100000\n",
    "BATCHES_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "FEATURE_SET = \"basic\"\n",
    "NUM_FEATURES = 768\n",
    "METHOD = \"eval\"\n",
    "\n",
    "if METHOD == \"pqr\":\n",
    "    X_SHAPE = (BATCH_SIZE, 3, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 0)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/pqr-1700/*.csv\")\n",
    "    loss_fn = PQRLoss()\n",
    "elif METHOD == \"eval\":\n",
    "    X_SHAPE = (BATCH_SIZE, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 1)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/eval/*.csv\")\n",
    "    loss_fn = EvalLoss()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder = f'runs/{timestamp}_{METHOD}_{FEATURE_SET}_{BATCH_SIZE}'\n",
    "os.makedirs(f'{folder}/models', exist_ok=True)\n",
    "\n",
    "samples_service = SamplesService(x_shape=X_SHAPE, y_shape=Y_SHAPE, inputs=INPUTS, feature_set=FEATURE_SET, method=METHOD)\n",
    "chessmodel = ChessModel(num_features=NUM_FEATURES)\n",
    "chessmodel.cuda()\n",
    "\n",
    "#for i in tqdm(range(1000000)):\n",
    "#    a = samples_service.next_batch()\n",
    "\n",
    "optimizer = torch.optim.Adam(chessmodel.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=0.0001, factor=0.7, patience=10)\n",
    "writer = SummaryWriter(folder)\n",
    "\n",
    "# @torch.compile # 30% speedup\n",
    "def train_step(X, y):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = chessmodel(X)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    chessmodel._clip_weights()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Make sure gradient tracking is on\n",
    "chessmodel.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _ in tqdm(range(BATCHES_PER_EPOCH), desc=f'Epoch {epoch}'):\n",
    "        X, y = samples_service.next_batch()\n",
    "    \n",
    "        # expand bitset\n",
    "        X = decode_int64_bitset(X)\n",
    "        X = X.reshape(-1, NUM_FEATURES)\n",
    "\n",
    "        loss = train_step(X, y)\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if math.isnan(avg_loss):\n",
    "            raise Exception(\"Loss is NaN, exiting\")\n",
    "\n",
    "    avg_loss /= BATCHES_PER_EPOCH\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    writer.add_scalar('Train/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/lr', scheduler._last_lr[0], epoch) # get_last_lr()\n",
    "    writer.add_scalar('Params/mean-l1', torch.mean(chessmodel.linear1.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l2', torch.mean(chessmodel.linear2.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l3', torch.mean(chessmodel.linear3.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l4', torch.mean(chessmodel.output.weight), epoch)\n",
    "    for name, param in chessmodel.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    # save model\n",
    "    torch.save(chessmodel.state_dict(), f'{folder}/models/{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(chessmodel.output.parameters())[0].cpu().detach().numpy()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# plot distribution\n",
    "sns.histplot(a.flatten(), kde=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
