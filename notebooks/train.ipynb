{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 11:44:55.767493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-21 11:44:55.767667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-21 11:44:55.818449: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-21 11:44:55.916684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lib.service import SamplesService\n",
    "from lib.model import NnueModel\n",
    "from lib.model import decode_int64_bitset\n",
    "from lib.serialize import NnueWriter\n",
    "from lib.puzzles import PuzzleAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING = 356.0\n",
    "\n",
    "class PQRLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PQRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, _target):\n",
    "        output = output.reshape(-1, 3)\n",
    "        \n",
    "        p = output[:,0] / SCALING\n",
    "        q = output[:,1] / SCALING\n",
    "        r = output[:,2] / SCALING\n",
    "        \n",
    "        a = -torch.mean(torch.log(torch.sigmoid(r - q)))\n",
    "        b = torch.mean(torch.square(p + q))\n",
    "\n",
    "        loss = a + b\n",
    "\n",
    "        return loss\n",
    "\n",
    "class EvalLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EvalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        # go from UCI cp to Stockfish's internal engine units\n",
    "        # https://github.com/official-stockfish/Stockfish/blob/fb07281f5590bc216ecbacd468aa0d06fdead70c/src/uci.cpp#L341\n",
    "        target = target * SCALING / 100.0\n",
    "\n",
    "        # targets are in CP-space change it to WDL-space [0, 1]\n",
    "        wdl_model = torch.sigmoid(output / SCALING)\n",
    "        wdl_target = torch.sigmoid(target / SCALING)\n",
    "\n",
    "        loss = torch.pow(torch.abs(wdl_model - wdl_target), 2.5)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100000\n",
    "BATCHES_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "FEATURE_SET = \"basic\"\n",
    "NUM_FEATURES = 768\n",
    "METHOD = \"eval\"\n",
    "\n",
    "if METHOD == \"pqr\":\n",
    "    X_SHAPE = (BATCH_SIZE, 3, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 0)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/pqr-1700/*.csv\")\n",
    "    loss_fn = PQRLoss()\n",
    "elif METHOD == \"eval\":\n",
    "    X_SHAPE = (BATCH_SIZE, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 1)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/eval/*.csv\")\n",
    "    loss_fn = EvalLoss()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder = f'runs/{timestamp}_{METHOD}_{FEATURE_SET}_{BATCH_SIZE}'\n",
    "os.makedirs(f'{folder}/models', exist_ok=True)\n",
    "\n",
    "puzzles = PuzzleAccuracy('/mnt/c/Users/mlomb/Desktop/Tesis/cs-master-thesis/puzzles.csv')\n",
    "samples_service = SamplesService(x_shape=X_SHAPE, y_shape=Y_SHAPE, inputs=INPUTS, feature_set=FEATURE_SET, method=METHOD)\n",
    "chessmodel = NnueModel(num_features=NUM_FEATURES)\n",
    "chessmodel.cuda()\n",
    "\n",
    "#for i in tqdm(range(1000000)):\n",
    "#    a = samples_service.next_batch()\n",
    "\n",
    "optimizer = torch.optim.Adam(chessmodel.parameters(), lr=0.0015)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=0.0001, factor=0.7, patience=10)\n",
    "writer = SummaryWriter(folder)\n",
    "\n",
    "# @torch.compile # 30% speedup\n",
    "def train_step(X, y):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = chessmodel(X)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    chessmodel.clip_weights()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Make sure gradient tracking is on\n",
    "chessmodel.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _ in tqdm(range(BATCHES_PER_EPOCH), desc=f'Epoch {epoch}'):\n",
    "        X, y = samples_service.next_batch()\n",
    "    \n",
    "        # expand bitset\n",
    "        X = decode_int64_bitset(X)\n",
    "        X = X.reshape(-1, 2, NUM_FEATURES)\n",
    "\n",
    "        loss = train_step(X, y)\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if math.isnan(avg_loss):\n",
    "            raise Exception(\"Loss is NaN, exiting\")\n",
    "\n",
    "    avg_loss /= BATCHES_PER_EPOCH\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # save model\n",
    "    model_path = f'{folder}/models/{epoch}'\n",
    "    model_pth = f'{model_path}.pth'\n",
    "    model_nn = f'{model_path}.nn'\n",
    "    torch.save(chessmodel.state_dict(), model_pth)\n",
    "    nn_writer = NnueWriter(chessmodel, FEATURE_SET)\n",
    "    with open(model_nn, \"wb\") as f:\n",
    "        f.write(nn_writer.buf)\n",
    "    \n",
    "    # run metrics\n",
    "    puzzles_ratings, puzzles_accuracy = puzzles.measure([\"/mnt/c/Users/mlomb/Desktop/Tesis/cs-master-thesis/bot/target/release/bot\", f\"--nn={model_nn}\"])\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar('Train/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/lr', scheduler._last_lr[0], epoch) # get_last_lr()\n",
    "    writer.add_scalar('Params/mean-f1', torch.mean(chessmodel.ft.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l1', torch.mean(chessmodel.linear1.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l2', torch.mean(chessmodel.linear2.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-out', torch.mean(chessmodel.output.weight), epoch)\n",
    "    for name, param in chessmodel.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "    writer.add_scalar(f'Puzzles/accuracy', puzzles_accuracy, epoch)\n",
    "    for rating_min, rating_max, accuracy in puzzles_ratings:\n",
    "        writer.add_scalar(f'Puzzles/{rating_min}-{rating_max}/accuracy', accuracy, epoch)\n",
    "\n",
    "    writer.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
