{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 20:28:38.963780: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 20:28:38.963833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 20:28:38.964838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 20:28:38.971424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 20:28:40.088474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lib.service import SamplesService\n",
    "from lib.model import NnueModel\n",
    "from lib.model import decode_int64_bitset\n",
    "from lib.serialize import NnueWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQRLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PQRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred):\n",
    "        pred = pred.reshape(-1, 3)\n",
    "        \n",
    "        p = pred[:,0]\n",
    "        q = pred[:,1]\n",
    "        r = pred[:,2]\n",
    "        \n",
    "        a = -torch.mean(torch.log(torch.sigmoid(r - q)))\n",
    "        b = torch.mean(torch.square(p + q))\n",
    "\n",
    "        loss = a + b\n",
    "\n",
    "        return loss\n",
    "\n",
    "class EvalLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EvalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        scaling = 356.0\n",
    "\n",
    "        # go from UCI cp to Stockfish's internal engine units\n",
    "        # https://github.com/official-stockfish/Stockfish/blob/fb07281f5590bc216ecbacd468aa0d06fdead70c/src/uci.cpp#L341\n",
    "        target = target * scaling / 100.0\n",
    "\n",
    "        # targets are in CP-space change it to WDL-space [0, 1]\n",
    "        wdl_model = torch.sigmoid(output / scaling)\n",
    "        wdl_target = torch.sigmoid(target / scaling)\n",
    "\n",
    "        loss = torch.pow(torch.abs(wdl_model - wdl_target), 2.5)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1000/1000 [00:13<00:00, 75.55it/s]\n",
      "Epoch 1: 100%|██████████| 1000/1000 [00:12<00:00, 82.50it/s]\n",
      "Epoch 2: 100%|██████████| 1000/1000 [00:13<00:00, 75.85it/s]\n",
      "Epoch 3: 100%|██████████| 1000/1000 [00:10<00:00, 93.39it/s]\n",
      "Epoch 4: 100%|██████████| 1000/1000 [00:11<00:00, 87.16it/s]\n",
      "Epoch 5: 100%|██████████| 1000/1000 [00:11<00:00, 87.81it/s]\n",
      "Epoch 6: 100%|██████████| 1000/1000 [00:12<00:00, 79.97it/s]\n",
      "Epoch 7: 100%|██████████| 1000/1000 [00:13<00:00, 75.01it/s]\n",
      "Epoch 8: 100%|██████████| 1000/1000 [00:12<00:00, 79.83it/s]\n",
      "Epoch 9: 100%|██████████| 1000/1000 [00:11<00:00, 90.13it/s]\n",
      "Epoch 10: 100%|██████████| 1000/1000 [00:11<00:00, 83.44it/s]\n",
      "Epoch 11: 100%|██████████| 1000/1000 [00:11<00:00, 85.08it/s]\n",
      "Epoch 12: 100%|██████████| 1000/1000 [00:11<00:00, 85.22it/s]\n",
      "Epoch 13: 100%|██████████| 1000/1000 [00:11<00:00, 84.94it/s]\n",
      "Epoch 14: 100%|██████████| 1000/1000 [00:10<00:00, 91.68it/s]\n",
      "Epoch 15: 100%|██████████| 1000/1000 [00:11<00:00, 84.13it/s]\n",
      "Epoch 16:  16%|█▌        | 162/1000 [00:01<00:09, 87.87it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "BATCHES_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "FEATURE_SET = \"basic\"\n",
    "NUM_FEATURES = 768\n",
    "METHOD = \"eval\"\n",
    "\n",
    "if METHOD == \"pqr\":\n",
    "    X_SHAPE = (BATCH_SIZE, 3, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 0)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/pqr-1700/*.csv\")\n",
    "    loss_fn = PQRLoss()\n",
    "elif METHOD == \"eval\":\n",
    "    X_SHAPE = (BATCH_SIZE, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 1)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/eval/*.csv\")\n",
    "    loss_fn = EvalLoss()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder = f'runs/{timestamp}_{METHOD}_{FEATURE_SET}_{BATCH_SIZE}'\n",
    "os.makedirs(f'{folder}/models', exist_ok=True)\n",
    "\n",
    "samples_service = SamplesService(x_shape=X_SHAPE, y_shape=Y_SHAPE, inputs=INPUTS, feature_set=FEATURE_SET, method=METHOD)\n",
    "chessmodel = NnueModel(num_features=NUM_FEATURES)\n",
    "chessmodel.cuda()\n",
    "\n",
    "#for i in tqdm(range(1000000)):\n",
    "#    a = samples_service.next_batch()\n",
    "\n",
    "optimizer = torch.optim.Adam(chessmodel.parameters(), lr=0.0015)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=0.0001, factor=0.7, patience=10)\n",
    "writer = SummaryWriter(folder)\n",
    "\n",
    "# @torch.compile # 30% speedup\n",
    "def train_step(X, y):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = chessmodel(X)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    chessmodel.clip_weights()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Make sure gradient tracking is on\n",
    "chessmodel.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _ in tqdm(range(BATCHES_PER_EPOCH), desc=f'Epoch {epoch}'):\n",
    "        X, y = samples_service.next_batch()\n",
    "    \n",
    "        # expand bitset\n",
    "        X = decode_int64_bitset(X)\n",
    "        X = X.reshape(-1, 2, NUM_FEATURES)\n",
    "\n",
    "        loss = train_step(X, y)\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if math.isnan(avg_loss):\n",
    "            raise Exception(\"Loss is NaN, exiting\")\n",
    "\n",
    "    avg_loss /= BATCHES_PER_EPOCH\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    writer.add_scalar('Train/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/lr', scheduler._last_lr[0], epoch) # get_last_lr()\n",
    "    writer.add_scalar('Params/mean-f1', torch.mean(chessmodel.ft.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l1', torch.mean(chessmodel.linear1.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l2', torch.mean(chessmodel.linear2.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-out', torch.mean(chessmodel.output.weight), epoch)\n",
    "    for name, param in chessmodel.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    # save model\n",
    "    model_path = f'{folder}/models/{epoch}'\n",
    "    torch.save(chessmodel.state_dict(), f'{model_path}.pth')\n",
    "    nn_writer = NnueWriter(chessmodel, FEATURE_SET)\n",
    "    with open(f'{model_path}.nn', \"wb\") as f:\n",
    "        f.write(nn_writer.buf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
