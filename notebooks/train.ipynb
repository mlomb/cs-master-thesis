{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 15:48:27.811908: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:27.812167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:27.812308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:27.812639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:27.812666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-23 15:48:27.812765: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:27.812795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 6562 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print([dev.name for dev in device_lib.list_local_devices()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 15:48:31.155557: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.155751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.155807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.156219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.156327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.156372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.156997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.157052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-01-23 15:48:31.157252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 15:48:31.157323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6562 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "def decode(tensor):\n",
    "    \"\"\"\n",
    "    Converts the 12 uint64s into a 768 float32 tensor.\n",
    "    \"\"\"\n",
    "    masks = tf.convert_to_tensor(2 ** np.arange(64, dtype=np.int64))\n",
    "    masked = tf.bitwise.bitwise_and(tf.expand_dims(tensor, -1), masks)\n",
    "    expanded = tf.cast(tf.not_equal(masked, 0), dtype=tf.float32)\n",
    "    return tf.reshape(expanded, (-1, 768))\n",
    "\n",
    "# read file\n",
    "dataset = tf.data.Dataset.list_files('../data/dataset/*.bin')\n",
    "dataset = tf.data.FixedLengthRecordDataset(dataset, record_bytes=3 * 12 * 8)\n",
    "dataset = dataset.map(lambda s: tf.reshape(tf.io.decode_raw(s, tf.int64), (3, 12)))\n",
    "# dataset = dataset.take(2)\n",
    "dataset = dataset.batch(4096)\n",
    "#dataset = dataset.map(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4096, 3, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataset.take(1)))\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 12, figsize=(18, 4))\n",
    "for kind in range(3):\n",
    "    for layer in range(12):\n",
    "        axs[kind][layer].imshow(decode(batch.numpy()[0]).numpy()[kind].reshape((12,8,8))[layer])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Concatenate, Lambda\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 12)]              0         \n",
      "                                                                 \n",
      " tf.expand_dims_12 (TFOpLam  (None, 12, 1)             0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " tf.bitwise.bitwise_and_12   (None, 12, 64)            0         \n",
      " (TFOpLambda)                                                    \n",
      "                                                                 \n",
      " tf.math.not_equal_12 (TFOp  (None, 12, 64)            0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " tf.cast_12 (TFOpLambda)     (None, 12, 64)            0         \n",
      "                                                                 \n",
      " tf.reshape_12 (TFOpLambda)  (None, 768)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 2048)              1574912   \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9969665 (38.03 MB)\n",
      "Trainable params: 9969665 (38.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)       [(None, 3, 12)]              0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 12)                   0         ['input_26[0][0]']            \n",
      " 6 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 12)                   0         ['input_26[0][0]']            \n",
      " 7 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 12)                   0         ['input_26[0][0]']            \n",
      " 8 (SlicingOpLambda)                                                                              \n",
      "                                                                                                  \n",
      " model_24 (Functional)       (None, 1)                    9969665   ['tf.__operators__.getitem_36[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_37[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'tf.__operators__.getitem_38[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9969665 (38.03 MB)\n",
      "Trainable params: 9969665 (38.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(_y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute loss as defined in https://erikbern.com/2014/11/29/deep-learning-for-chess.html\n",
    "    // sum(p,q,r)logS(f(q)−f(r))+K*log(f(p)+f(q))+K*log(−f(q)−f(p))\n",
    "    \"\"\"\n",
    "    p = y_pred[0]\n",
    "    q = y_pred[1]\n",
    "    r = y_pred[2]\n",
    "    K = 10.0\n",
    "\n",
    "    a = - tf.math.log(tf.math.sigmoid(q - r))\n",
    "    b = - K * tf.math.log(tf.math.sigmoid(p + q))\n",
    "    c = - K * tf.math.log(tf.math.sigmoid(-q - p))\n",
    "\n",
    "    return a + b + c\n",
    "\n",
    "def make_chess_model():\n",
    "    inp = tf.keras.Input(shape=(12,), dtype=tf.int64)\n",
    "    x = decode(inp) # convert 12 ints to 768 floats\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(1)(x)\n",
    "    return Model(inp, x)\n",
    "\n",
    "def make_siamese_model(chess_model):\n",
    "    boards = tf.keras.Input(shape=(3, 12), dtype=tf.int64)\n",
    "\n",
    "    p_board = boards[:, 0, :]\n",
    "    q_board = boards[:, 1, :]\n",
    "    r_board = boards[:, 2, :]\n",
    "\n",
    "    p = chess_model(p_board)\n",
    "    q = chess_model(q_board)\n",
    "    r = chess_model(r_board)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[boards],\n",
    "        outputs=[p, q, r]\n",
    "    )\n",
    "    model.compile('adam', loss=custom_loss, metrics=[])\n",
    "    return model\n",
    "\n",
    "chess_model = make_chess_model()\n",
    "train_model = make_siamese_model(chess_model)\n",
    "chess_model.summary()\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[0.13650724],\n",
       "       [0.12047085],\n",
       "       [0.11492033]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.13650723],\n",
       "        [0.01309171],\n",
       "        [0.05350399],\n",
       "        ...,\n",
       "        [0.1338489 ],\n",
       "        [0.04396537],\n",
       "        [0.10186657]], dtype=float32),\n",
       " array([[0.12047089],\n",
       "        [0.09634117],\n",
       "        [0.04116507],\n",
       "        ...,\n",
       "        [0.1446475 ],\n",
       "        [0.08069891],\n",
       "        [0.06396127]], dtype=float32),\n",
       " array([[0.11492033],\n",
       "        [0.09494121],\n",
       "        [0.06105151],\n",
       "        ...,\n",
       "        [0.13308671],\n",
       "        [0.06717613],\n",
       "        [0.07955478]], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "738/738 [==============================] - 100s 136ms/step - loss: 43.6742 - model_24_loss: 14.5574 - model_24_1_loss: 14.5583 - model_24_2_loss: 14.5584\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 16:12:20.707885: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11179685076252936827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/738 [=========>....................] - ETA: 1:07 - loss: 43.6663 - model_24_loss: 14.5563 - model_24_1_loss: 14.5548 - model_24_2_loss: 14.5551"
     ]
    }
   ],
   "source": [
    "history = train_model.fit(\n",
    "    dataset.map(lambda x : (x, tf.constant([0.0]))),\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
