{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print([dev.name for dev in device_lib.list_local_devices()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from lib.encoding import decode_board, encode_board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "dataset = tf.data.Dataset.list_files('../data/dataset/*.bin', shuffle=True, seed=42)\n",
    "dataset = tf.data.FixedLengthRecordDataset(dataset, record_bytes=3 * 12 * 8)\n",
    "dataset = dataset.map(lambda s: tf.reshape(tf.io.decode_raw(s, tf.int64), (3, 12)))\n",
    "dataset = dataset.take(800_000)\n",
    "# dataset = dataset.shuffle(4096)\n",
    "dataset = dataset.batch(4096).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4096, 3, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataset.take(1)))\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 12, figsize=(18, 4))\n",
    "for kind in range(3):\n",
    "    for layer in range(12):\n",
    "        axs[kind][layer].imshow(decode_board(batch.numpy()[0]).numpy()[kind].reshape((12,8,8))[layer])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 12)]              0         \n",
      "                                                                 \n",
      " tf.expand_dims (TFOpLambda  (None, 12, 1)             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.bitwise.bitwise_and (TF  (None, 12, 64)            0         \n",
      " OpLambda)                                                       \n",
      "                                                                 \n",
      " tf.math.not_equal (TFOpLam  (None, 12, 64)            0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 12, 64)            0         \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              1574912   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9969665 (38.03 MB)\n",
      "Trainable params: 9969665 (38.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 12)]              0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 12)                   0         ['input_2[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 12)                   0         ['input_2[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 12)                   0         ['input_2[0][0]']             \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 1)                    9969665   ['tf.__operators__.getitem[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9969665 (38.03 MB)\n",
      "Trainable params: 9969665 (38.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def custom_loss(_y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute loss as defined in https://erikbern.com/2014/11/29/deep-learning-for-chess.html\n",
    "    // sum(p,q,r)logS(f(q)−f(r))+K*log(f(p)+f(q))+K*log(−f(q)−f(p))\n",
    "    \"\"\"\n",
    "    p = y_pred[0]\n",
    "    q = y_pred[1]\n",
    "    r = y_pred[2]\n",
    "    K = 10.0\n",
    "\n",
    "    a = - tf.math.log(tf.math.sigmoid(q - r))\n",
    "    b = - K * tf.math.log(tf.math.sigmoid(p + q))\n",
    "    c = - K * tf.math.log(tf.math.sigmoid(-q - p))\n",
    "\n",
    "    return a + b + c\n",
    "\n",
    "def make_chess_model():\n",
    "    inp = tf.keras.Input(shape=(12,), dtype=tf.int64)\n",
    "    x = decode_board(inp) # convert 12 ints to 768 floats\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(2048, activation=\"relu\")(x)\n",
    "    x = Dense(1)(x)\n",
    "    return Model(inp, x)\n",
    "\n",
    "def make_siamese_model(chess_model):\n",
    "    boards = tf.keras.Input(shape=(3, 12), dtype=tf.int64)\n",
    "\n",
    "    p_board = boards[:, 0, :]\n",
    "    q_board = boards[:, 1, :]\n",
    "    r_board = boards[:, 2, :]\n",
    "\n",
    "    p = chess_model(p_board)\n",
    "    q = chess_model(q_board)\n",
    "    r = chess_model(r_board)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[boards],\n",
    "        outputs=[p, q, r]\n",
    "    )\n",
    "    model.compile('adam', loss=custom_loss, metrics=[])\n",
    "    return model\n",
    "\n",
    "chess_model = make_chess_model()\n",
    "train_model = make_siamese_model(chess_model)\n",
    "chess_model.summary()\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-0.08618897],\n",
       "       [-0.09361   ],\n",
       "       [-0.11123157]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.08618896],\n",
       "        [-0.08712292],\n",
       "        [-0.09046108],\n",
       "        ...,\n",
       "        [-0.08707104],\n",
       "        [-0.11156046],\n",
       "        [-0.04786311]], dtype=float32),\n",
       " array([[-0.09361004],\n",
       "        [-0.03727897],\n",
       "        [-0.02713398],\n",
       "        ...,\n",
       "        [-0.04012894],\n",
       "        [-0.11379418],\n",
       "        [-0.06031183]], dtype=float32),\n",
       " array([[-0.11123155],\n",
       "        [-0.04732921],\n",
       "        [-0.05262522],\n",
       "        ...,\n",
       "        [-0.08254088],\n",
       "        [-0.12171945],\n",
       "        [-0.04711935]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.predict(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1706300225.740821   20973 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 35s 148ms/step - loss: 44.2652 - model_loss: 14.7530 - model_1_loss: 14.7513 - model_2_loss: 14.7609\n",
      "Epoch 2/9999\n",
      "196/196 [==============================] - 98s 503ms/step - loss: 43.6770 - model_loss: 14.5588 - model_1_loss: 14.5588 - model_2_loss: 14.5594\n",
      "Epoch 3/9999\n",
      "196/196 [==============================] - 77s 390ms/step - loss: 43.6732 - model_loss: 14.5577 - model_1_loss: 14.5576 - model_2_loss: 14.5579\n",
      "Epoch 4/9999\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 43.6742 - model_loss: 14.5668 - model_1_loss: 14.5527 - model_2_loss: 14.5547\n",
      "Epoch 5/9999\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 43.6712 - model_loss: 14.5570 - model_1_loss: 14.5571 - model_2_loss: 14.5570\n",
      "Epoch 6/9999\n",
      " 11/196 [>.............................] - ETA: 31s - loss: 43.6695 - model_loss: 14.5559 - model_1_loss: 14.5565 - model_2_loss: 14.5571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, TensorBoard\n\u001b[1;32m      4\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(time())\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9999\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mts\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/model-\u001b[39;49m\u001b[38;5;132;43;01m{epoch:02d}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{loss:.2f}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensorBoard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mts\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:394\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:360\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "ts = int(time())\n",
    "\n",
    "history = train_model.fit(\n",
    "    dataset.map(lambda x : (x, tf.constant([0.0]))),\n",
    "    epochs=9999,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(f\"checkpoints/{ts}\" + \"/model-{epoch:02d}-{loss:.2f}.keras\"),\n",
    "        TensorBoard(log_dir=f\"./logs/{ts}\", write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
