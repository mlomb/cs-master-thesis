{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3.11' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lib.service import SamplesService\n",
    "from lib.model import NnueModel\n",
    "from lib.model import decode_int64_bitset\n",
    "from lib.serialize import NnueWriter\n",
    "from lib.puzzles import PuzzleAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3.11' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "SCALING = 356.0\n",
    "\n",
    "class PQRLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PQRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, _target):\n",
    "        output = output.reshape(-1, 3)\n",
    "        \n",
    "        p = output[:,0] / SCALING\n",
    "        q = output[:,1] / SCALING\n",
    "        r = output[:,2] / SCALING\n",
    "        \n",
    "        a = -torch.mean(torch.log(torch.sigmoid(r - q)))\n",
    "        b = torch.mean(torch.square(p + q))\n",
    "\n",
    "        loss = a + b\n",
    "\n",
    "        return loss\n",
    "\n",
    "class EvalLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EvalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        # go from UCI cp to Stockfish's internal engine units\n",
    "        # https://github.com/official-stockfish/Stockfish/blob/fb07281f5590bc216ecbacd468aa0d06fdead70c/src/uci.cpp#L341\n",
    "        target = target * SCALING / 100.0\n",
    "\n",
    "        # targets are in CP-space change it to WDL-space [0, 1]\n",
    "        wdl_model = torch.sigmoid(output / SCALING)\n",
    "        wdl_target = torch.sigmoid(target / SCALING)\n",
    "\n",
    "        loss = torch.pow(torch.abs(wdl_model - wdl_target), 2.5)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3.11' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "BATCHES_PER_EPOCH = 1000\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "FEATURE_SET = \"basic\"\n",
    "NUM_FEATURES = 768\n",
    "METHOD = \"pqr\"\n",
    "\n",
    "if METHOD == \"pqr\":\n",
    "    X_SHAPE = (BATCH_SIZE, 3, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 0)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/pqr-1700/*.csv\")\n",
    "    loss_fn = PQRLoss()\n",
    "elif METHOD == \"eval\":\n",
    "    X_SHAPE = (BATCH_SIZE, 2, NUM_FEATURES // 64)\n",
    "    Y_SHAPE = (BATCH_SIZE, 1)\n",
    "    INPUTS = glob(\"/mnt/d/datasets/eval/*.csv\")\n",
    "    loss_fn = EvalLoss()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder = f'runs/{timestamp}_{METHOD}_{FEATURE_SET}_{BATCH_SIZE}'\n",
    "os.makedirs(f'{folder}/models', exist_ok=True)\n",
    "\n",
    "puzzles = PuzzleAccuracy('/mnt/c/Users/mlomb/OneDrive/Escritorio/cs-master-thesis/puzzles.csv')\n",
    "samples_service = SamplesService(x_shape=X_SHAPE, y_shape=Y_SHAPE, inputs=INPUTS, feature_set=FEATURE_SET, method=METHOD)\n",
    "chessmodel = NnueModel(num_features=NUM_FEATURES)\n",
    "chessmodel.cuda()\n",
    "\n",
    "#for i in tqdm(range(1000000)):\n",
    "#    a = samples_service.next_batch()\n",
    "\n",
    "optimizer = torch.optim.Adam(chessmodel.parameters(), lr=0.0015)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold=0.0001, factor=0.7, patience=10)\n",
    "writer = SummaryWriter(folder)\n",
    "\n",
    "# @torch.compile # 30% speedup\n",
    "def train_step(X, y):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = chessmodel(X)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    chessmodel.clip_weights()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Make sure gradient tracking is on\n",
    "chessmodel.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _ in tqdm(range(BATCHES_PER_EPOCH), desc=f'Epoch {epoch}'):\n",
    "        X, y = samples_service.next_batch()\n",
    "    \n",
    "        # expand bitset\n",
    "        X = decode_int64_bitset(X)\n",
    "        X = X.reshape(-1, 2, NUM_FEATURES)\n",
    "\n",
    "        loss = train_step(X, y)\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if math.isnan(avg_loss):\n",
    "            raise Exception(\"Loss is NaN, exiting\")\n",
    "\n",
    "    avg_loss /= BATCHES_PER_EPOCH\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # save model\n",
    "    model_path = f'{folder}/models/{epoch}'\n",
    "    model_pth = f'{model_path}.pth'\n",
    "    model_nn = f'{model_path}.nn'\n",
    "    torch.save(chessmodel.state_dict(), model_pth)\n",
    "    nn_writer = NnueWriter(chessmodel, FEATURE_SET)\n",
    "    with open(model_nn, \"wb\") as f:\n",
    "        f.write(nn_writer.buf)\n",
    "    \n",
    "    # run metrics\n",
    "    puzzles_res = puzzles.measure(model_nn)\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar('Train/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/lr', scheduler._last_lr[0], epoch) # get_last_lr()\n",
    "    writer.add_scalar('Params/mean-f1', torch.mean(chessmodel.ft.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l1', torch.mean(chessmodel.linear1.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l2', torch.mean(chessmodel.linear2.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-out', torch.mean(chessmodel.output.weight), epoch)\n",
    "    for name, param in chessmodel.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "    writer.flush()\n",
    "    for rating_min, rating_max, accuracy in puzzles_res.items():\n",
    "        writer.add_scalar(f'Puzzles/{rating_min}-{rating_max}/accuracy', accuracy, epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
