{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from lib.service import SamplesService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChessModel(\n",
      "  (activation): ReLU()\n",
      "  (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "  (linear2): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (linear4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def decode_int64_bitset(x):\n",
    "    \"\"\"\n",
    "    Convert a 64-bit integer into a 64-element float tensor\n",
    "    \"\"\"\n",
    "    masks = 2 ** torch.arange(64, dtype=torch.int64, device='cuda')\n",
    "    expanded = torch.bitwise_and(x.unsqueeze(-1), masks).ne(0).to(torch.float32)\n",
    "    return expanded\n",
    "\n",
    "class ChessModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(ChessModel, self).__init__()\n",
    "        \n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear1 = torch.nn.Linear(num_features, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 64)\n",
    "        self.linear3 = torch.nn.Linear(64, 64)\n",
    "        self.linear4 = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "chessmodel = ChessModel(num_features=768)\n",
    "chessmodel.cuda()\n",
    "\n",
    "print(chessmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQRLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PQRLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.reshape(-1, 3)\n",
    "        \n",
    "        p = inputs[:,0]\n",
    "        q = inputs[:,1]\n",
    "        r = inputs[:,2]\n",
    "        \n",
    "        a = -torch.mean(torch.log(torch.sigmoid(r - q)))\n",
    "        b = torch.mean(torch.square(p + q))\n",
    "\n",
    "        loss = a + b\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 15:34:16.254562: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 15:34:16.254686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 15:34:16.265653: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 15:34:16.308352: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 15:34:17.287115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Epoch 0:   0%|          | 6/3000 [00:00<04:12, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6970961093902588\n",
      "tensor(0.6942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6942439079284668\n",
      "tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6935494542121887\n",
      "tensor(0.6931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.693077802658081\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6932233572006226\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6931798458099365\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6929364800453186\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6928325295448303\n",
      "tensor(0.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6928582787513733\n",
      "tensor(0.6928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6928172707557678\n",
      "tensor(0.6926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6926230192184448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 18/3000 [00:00<01:36, 30.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6924653649330139\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6924282312393188\n",
      "tensor(0.6923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6923004984855652\n",
      "tensor(0.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6920188069343567\n",
      "tensor(0.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6919196248054504\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.691828191280365\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6916108131408691\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6913023591041565\n",
      "tensor(0.6910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6909537315368652\n",
      "tensor(0.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6905672550201416\n",
      "tensor(0.6902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6902071833610535\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6894310712814331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 31/3000 [00:01<01:08, 43.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6888781785964966\n",
      "tensor(0.6884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6884173154830933\n",
      "tensor(0.6879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6878847479820251\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6869296431541443\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.68623948097229\n",
      "tensor(0.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6858070492744446\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6853053569793701\n",
      "tensor(0.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6846150755882263\n",
      "tensor(0.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6833410263061523\n",
      "tensor(0.6815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6814746260643005\n",
      "tensor(0.6814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6813890337944031\n",
      "tensor(0.6800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6799975037574768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|▏         | 43/3000 [00:01<00:58, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6815463900566101\n",
      "tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.681839108467102\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6788350343704224\n",
      "tensor(0.6789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6789047122001648\n",
      "tensor(0.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.677987277507782\n",
      "tensor(0.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6757647395133972\n",
      "tensor(0.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.677666425704956\n",
      "tensor(0.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6759375929832458\n",
      "tensor(0.6751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6750903129577637\n",
      "tensor(0.6732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6731860637664795\n",
      "tensor(0.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6738492250442505\n",
      "tensor(0.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6733296513557434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 52/3000 [00:01<01:23, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6722923517227173\n",
      "tensor(0.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6722132563591003\n",
      "tensor(0.6725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6725433468818665\n",
      "tensor(0.6702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.670182466506958\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.6693065762519836\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m batch \u001b[38;5;241m=\u001b[39m decode_int64_bitset(batch)\n\u001b[1;32m     44\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m768\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     48\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Update the parameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    423\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    635\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    566\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    570\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCHES_PER_EPOCH = 3_000\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "samples_service = SamplesService(batch_size=BATCH_SIZE)\n",
    "optimizer = torch.optim.Adam(chessmodel.parameters(), lr=0.001)\n",
    "loss_fn = PQRLoss()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/{}'.format(timestamp))\n",
    "\n",
    "# @torch.compile\n",
    "def train_step(batch):\n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = chessmodel(batch)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(outputs)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Make sure gradient tracking is on\n",
    "chessmodel.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _ in tqdm(range(BATCHES_PER_EPOCH), desc=f'Epoch {epoch}'):\n",
    "        batch = samples_service.next_batch()\n",
    "        batch = decode_int64_bitset(batch)\n",
    "        batch = batch.reshape(-1, 768)\n",
    "\n",
    "        loss = train_step(batch)\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if math.isnan(avg_loss):\n",
    "            raise Exception(\"Loss is NaN, exiting\")\n",
    "\n",
    "    avg_loss /= BATCHES_PER_EPOCH\n",
    "\n",
    "    writer.add_scalar('Train/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/lr', optimizer.param_groups[0][\"lr\"], epoch)\n",
    "    writer.add_scalar('Params/mean-l1', torch.mean(chessmodel.linear1.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l2', torch.mean(chessmodel.linear2.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l3', torch.mean(chessmodel.linear3.weight), epoch)\n",
    "    writer.add_scalar('Params/mean-l4', torch.mean(chessmodel.linear4.weight), epoch)\n",
    "    for name, param in chessmodel.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "    writer.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
